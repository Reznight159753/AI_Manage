import React, { Suspense, useEffect, useRef, useState, useMemo } from 'react';
import { useNavigate } from 'react-router-dom';
import { Canvas, useFrame } from '@react-three/fiber';
import { useGLTF, useTexture, Loader, Environment, useFBX, useAnimations, OrthographicCamera } from '@react-three/drei';
import { MeshStandardMaterial } from 'three/src/materials/MeshStandardMaterial';
import { LineBasicMaterial, MeshPhysicalMaterial, Vector2 } from 'three';
import ReactAudioPlayer from 'react-audio-player';
import createAnimation from '../converter';
import blinkData from '../blendDataBlink.json';
import * as THREE from 'three';
import axios from 'axios';
import { SRGBColorSpace, LinearSRGBColorSpace } from 'three';
import './ModelDesign.css';
const _ = require('lodash');

const host = 'http://localhost:5000'; // Server TTS

// AI Endpoints - s·ª≠ d·ª•ng proxy ƒë·ªÉ tr√°nh CORS
const AI_ENDPOINTS = [
  //'http://localhost:3001/api/ai',  // Proxy server
  'http://192.168.1.32:8000'      // Fallback: Direct connection
];

// Utility function ƒë·ªÉ t·∫°o UUID v4
function generateUUID() {
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    var r = Math.random() * 16 | 0;
    var v = c == 'x' ? r : (r & 0x3 | 0x8);
    return v.toString(16);
  });
}

// H√†m l√†m s·∫°ch vƒÉn b·∫£n t·∫°i frontend - ch·ªâ lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát nguy hi·ªÉm
function cleanText(text) {
  return text
    .replace(/[\uD800-\uDFFF]/g, '') // Lo·∫°i b·ªè surrogate characters
    .replace(/[^\x20-\x7E\u00C0-\u1EF9\s.,!?\-()]/g, '') // Gi·ªØ ASCII, ti·∫øng Vi·ªát, d·∫•u c√¢u, d·∫•u c√°ch
    .trim();
}

function Avatar({ avatar_url, speak, setSpeak, text, setAudioSource, playing }) {
  let gltf = useGLTF(avatar_url);
  let morphTargetDictionaryBody = null;
  let morphTargetDictionaryLowerTeeth = null;

  const [
    bodyTexture, eyesTexture, teethTexture, bodySpecularTexture, bodyRoughnessTexture,
    bodyNormalTexture, teethNormalTexture, hairTexture, tshirtDiffuseTexture,
    tshirtNormalTexture, tshirtRoughnessTexture, hairAlphaTexture, hairNormalTexture,
    hairRoughnessTexture,
  ] = useTexture([
    "/images/body.webp", "/images/eyes.webp", "/images/teeth_diffuse.webp",
    "/images/body_specular.webp", "/images/body_roughness.webp", "/images/body_normal.webp",
    "/images/teeth_normal.webp", "/images/h_color.webp", "/images/tshirt_diffuse.webp",
    "/images/tshirt_normal.webp", "/images/tshirt_roughness.webp", "/images/h_alpha.webp",
    "/images/h_normal.webp", "/images/h_roughness.webp",
  ]);

  _.each([
    bodyTexture, eyesTexture, teethTexture, teethNormalTexture, bodySpecularTexture,
    bodyRoughnessTexture, bodyNormalTexture, tshirtDiffuseTexture, tshirtNormalTexture,
    tshirtRoughnessTexture, hairAlphaTexture, hairNormalTexture, hairRoughnessTexture,
  ], t => {
    t.colorSpace = SRGBColorSpace;
    t.flipY = false;
  });

  bodyNormalTexture.colorSpace = LinearSRGBColorSpace;
  tshirtNormalTexture.colorSpace = LinearSRGBColorSpace;
  teethNormalTexture.colorSpace = LinearSRGBColorSpace;
  hairNormalTexture.colorSpace = LinearSRGBColorSpace;

  gltf.scene.traverse(node => {
    if (node.type === 'Mesh' || node.type === 'LineSegments' || node.type === 'SkinnedMesh') {
      node.castShadow = true;
      node.receiveShadow = true;
      node.frustumCulled = false;

      if (node.name.includes("Body")) {
        node.material = new MeshPhysicalMaterial();
        node.material.map = bodyTexture;
        node.material.roughness = 1.7;
        node.material.roughnessMap = bodyRoughnessTexture;
        node.material.normalMap = bodyNormalTexture;
        node.material.normalScale = new Vector2(0.6, 0.6);
        node.material.color.setHex(0xF8E0A0);
        node.material.envMapIntensity = 0.8;
        morphTargetDictionaryBody = node.morphTargetDictionary;

        if (morphTargetDictionaryBody && morphTargetDictionaryBody['chinNarrow']) {
          node.morphTargetInfluences = node.morphTargetInfluences || [];
          node.morphTargetInfluences[morphTargetDictionaryBody['chinNarrow']] = 0.6;
        }
      }

      if (node.name.includes("Eyes")) {
        node.material = new MeshStandardMaterial();
        node.material.map = eyesTexture;
        node.material.roughness = 0.1;
        node.material.envMapIntensity = 0.5;
      }

      if (node.name.includes("Brows")) {
        node.material = new LineBasicMaterial({ color: 0x000000 });
        node.material.linewidth = 1;
        node.material.opacity = 0.5;
        node.material.transparent = true;
        node.visible = false;
      }

      if (node.name.includes("Teeth")) {
        node.material = new MeshStandardMaterial();
        node.material.roughness = 0.1;
        node.material.map = teethTexture;
        node.material.normalMap = teethNormalTexture;
        node.material.envMapIntensity = 0.7;
      }

      if (node.name.includes("Hair")) {
        node.material = new MeshStandardMaterial();
        node.material.map = hairTexture;
        node.material.alphaMap = hairAlphaTexture;
        node.material.normalMap = hairNormalTexture;
        node.material.roughnessMap = hairRoughnessTexture;
        node.material.transparent = true;
        node.material.depthWrite = false;
        node.material.side = 2;
        node.material.color.setHex(0x000000);
        node.material.envMapIntensity = 0.0;
      }

      if (node.name.includes("TSHIRT")) {
        node.material = new MeshStandardMaterial();
        node.material.map = tshirtDiffuseTexture;
        node.material.roughnessMap = tshirtRoughnessTexture;
        node.material.normalMap = tshirtNormalTexture;
        node.material.color.setHex(0xFFE4C4);
        node.material.envMapIntensity = 0.5;
      }

      if (node.name.includes("TeethLower")) {
        morphTargetDictionaryLowerTeeth = node.morphTargetDictionary;
      }
    }
  });

  const [clips, setClips] = useState([]);
  const mixer = useMemo(() => new THREE.AnimationMixer(gltf.scene), []);

  useEffect(() => {
    if (!speak) return;
    console.log('G·ª≠i vƒÉn b·∫£n t·ªõi server TTS:', text);
    makeSpeech(text)
      .then(response => {
        let { blendData, filename } = response.data;
        let newClips = [
          createAnimation(blendData, morphTargetDictionaryBody, 'HG_Body'),
          createAnimation(blendData, morphTargetDictionaryLowerTeeth, 'HG_TeethLower')
        ];
        filename = `${host}${filename}?t=${Date.now()}`;
        console.log('File MP3:', filename);
        setClips(newClips);
        setAudioSource(filename);
        setSpeak(false);
      })
      .catch(err => {
        console.error('L·ªói khi t·∫°o √¢m thanh:', err.message);
        setSpeak(false);
      });
  }, [speak, text, setAudioSource]);

  let idleFbx = useFBX('/idle.fbx');
  let { clips: idleClips } = useAnimations(idleFbx.animations);

  idleClips[0].tracks = _.filter(idleClips[0].tracks, track => {
    return track.name.includes("Head") || track.name.includes("Neck") || track.name.includes("Spine2");
  });

  idleClips[0].tracks = _.map(idleClips[0].tracks, track => {
    if (track.name.includes("Head")) track.name = "head.quaternion";
    if (track.name.includes("Neck")) track.name = "neck.quaternion";
    if (track.name.includes("Spine")) track.name = "spine2.quaternion";
    return track;
  });

  useEffect(() => {
    let idleClipAction = mixer.clipAction(idleClips[0]);
    idleClipAction.play();
    let blinkClip = createAnimation(blinkData, morphTargetDictionaryBody, 'HG_Body');
    let blinkAction = mixer.clipAction(blinkClip);
    blinkAction.play();
  }, [mixer]);

  useEffect(() => {
    if (!playing) return;
    _.each(clips, clip => {
      let clipAction = mixer.clipAction(clip);
      clipAction.setLoop(THREE.LoopOnce);
      clipAction.play();
    });
  }, [playing, clips]);

  useFrame((state, delta) => {
    mixer.update(delta);
  });

  return (
    <group name="avatar">
      <primitive object={gltf.scene} dispose={null} position={[-0.1, 0.5, 0]} scale={[0.6, 0.6, 0.6]} />
    </group>
  );
}

// H√†m g·ªçi API TTS (gi·ªØ nguy√™n)
function makeSpeech(text) {
  const cleanedText = cleanText(text);
  console.log('VƒÉn b·∫£n g·ª≠i ƒëi TTS:', cleanedText);
  if (!cleanedText) {
    console.error('L·ªói: VƒÉn b·∫£n sau khi l√†m s·∫°ch l√† r·ªóng');
    return Promise.reject(new Error('VƒÉn b·∫£n r·ªóng sau khi l√†m s·∫°ch'));
  }
  return axios.post(host + '/talk', { text: cleanedText, language: 'vi-VN', voice: 'vi-VN-HoaiMy' });
}

// H√†m g·ªçi API AI Assistant v·ªõi React proxy
async function callAIAssistant(userInput, sessionId) {
  console.log('üî• Starting AI Assistant call...');
  
  // S·ª≠ d·ª•ng relative URL khi c√≥ proxy trong package.json
  const endpoints = [
    '/ask',  // React proxy s·∫Ω forward ƒë·∫øn http://192.168.1.31:8000
    'http://localhost:3001/api/ai/ask',  // Proxy server backup
    'http://192.168.1.31:8000/ask'       // Direct connection backup
  ];
  
  for (const endpoint of endpoints) {
    try {
      console.log(`üîå Attempting connection to: ${endpoint}`);
      
      // T·∫°o axios instance v·ªõi c·∫•u h√¨nh CORS t·ªët h∆°n
      const axiosConfig = {
        timeout: 15000, // TƒÉng timeout l√™n 15s
        headers: {
          'Content-Type': 'application/json',
          'Accept': 'application/json',
          // Th√™m headers ƒë·ªÉ bypass m·ªôt s·ªë CORS issues
          'Access-Control-Allow-Origin': '*',
          'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',
          'Access-Control-Allow-Headers': 'Content-Type'
        },
        // T·∫Øt credentials ƒë·ªÉ tr√°nh CORS preflight
        withCredentials: false,
        // Th√™m c·∫•u h√¨nh ƒë·ªÉ handle c√°c network issues
        validateStatus: function (status) {
          return status >= 200 && status < 300; // Ch·ªâ accept status codes t·ª´ 200-299
        }
      };

      console.log('üì§ Sending request with data:', { 
        user_input: userInput, 
        session_id: sessionId 
      });

      const response = await axios.post(endpoint, {
        user_input: userInput,
        session_id: sessionId
      }, axiosConfig);
      
      console.log('‚úÖ Response received:', response.data);
      
      // Ki·ªÉm tra response data
      if (response.data && response.data.response) {
        console.log('üéâ Successfully got AI response');
        return response.data.response;
      } else {
        console.warn('‚ö†Ô∏è Response kh√¥ng c√≥ data.response field');
        return response.data || 'Ph·∫£n h·ªìi kh√¥ng h·ª£p l·ªá t·ª´ server.';
      }
      
    } catch (error) {
      console.error(`‚ùå Error with ${endpoint}:`, error);
      
      // Log chi ti·∫øt c√°c lo·∫°i l·ªói
      if (error.code === 'ECONNREFUSED') {
        console.log('üö´ Connection refused - Server may be offline');
      } else if (error.code === 'ERR_NETWORK') {
        console.log('üö´ Network error - Possible CORS issue');
      } else if (error.code === 'ENOTFOUND') {
        console.log('üö´ Host not found - Check IP address');
      } else if (error.response) {
        console.log(`üì° Server error: ${error.response.status} - ${error.response.statusText}`);
        console.log('Response data:', error.response.data);
      } else if (error.request) {
        console.log('üì§ Request made but no response received');
        console.log('Request config:', error.config);
      } else {
        console.log('‚ùì Unknown error:', error.message);
      }
      
      // Continue v·ªõi endpoint ti·∫øp theo thay v√¨ return ngay
      continue;
    }
  }
  
  // N·∫øu t·∫•t c·∫£ endpoints ƒë·ªÅu fail
  console.log('üí• All endpoints failed');
  return `Xin l·ªói, t√¥i kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server AI l√∫c n√†y. V·ªÅ "${userInput}", t√¥i s·∫Ω c·ªë g·∫Øng h·ªó tr·ª£ b·∫°n khi k·∫øt n·ªëi ƒë∆∞·ª£c kh√¥i ph·ª•c. Vui l√≤ng ki·ªÉm tra:
  
1. Server AI c√≥ ƒëang ch·∫°y kh√¥ng?
2. ƒê·ªãa ch·ªâ IP 192.168.1.31:8000 c√≥ ƒë√∫ng kh√¥ng?
3. Firewall/CORS c√≥ ƒëang ch·∫∑n kh√¥ng?`;
}

function Bg() {
  const texture = useTexture('/images/bg.webp');
  return (
    <mesh position={[0, 1.5, -2.5]}>
      <planeGeometry args={[1.4, 0.788]} />
      <meshBasicMaterial map={texture} />
    </mesh>
  );
}

function ModelDesign() {
  const navigate = useNavigate();
  const audioPlayer = useRef();
  const chatAreaRef = useRef();
  
  // Session ID - t·∫°o UUID duy nh·∫•t cho m·ªói phi√™n
  const [sessionId] = useState(() => generateUUID());
  
  // States cho model 3D
  const [speak, setSpeak] = useState(false);
  const [text, setText] = useState("");
  const [speechText, setSpeechText] = useState("");
  const [audioSource, setAudioSource] = useState(null);
  const [playing, setPlaying] = useState(false);
  
  // State cho m√†n h√¨nh mobile
  const [isMobile, setIsMobile] = useState(false);
  
  // State cho hi·ªáu ·ª©ng typing animation
  const [displayedText, setDisplayedText] = useState("");
  const [isTyping, setIsTyping] = useState(false);
  const typingSpeed = 30; // T·ªëc ƒë·ªô typing c·ªë ƒë·ªãnh (ms)
  
  // State cho tr·∫°ng th√°i loading
  const [isProcessing, setIsProcessing] = useState(false);
  
  // State cho connection status
  const [connectionStatus, setConnectionStatus] = useState('checking');
  
  // States cho chat interface
  const [messages, setMessages] = useState([
    {
      id: 1,
      type: 'ai',
      content: 'Xin ch√†o! T√¥i l√† Arwen, tr·ª£ l√Ω AI c·ªßa b·∫°n. T√¥i c√≥ th·ªÉ tr√≤ chuy·ªán v√† tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa b·∫°n. H√£y nh·∫≠p tin nh·∫Øn ƒë·ªÉ b·∫Øt ƒë·∫ßu!',
      timestamp: new Date()
    }
  ]);
  const [currentTime, setCurrentTime] = useState(
    new Date().toLocaleTimeString('en-US', { 
      hour: '2-digit', 
      minute: '2-digit', 
      second: '2-digit', 
      hour12: true 
    }) + ' +07, ' + new Date().toLocaleDateString('en-GB')
  );

  // Test connection khi component mount
  useEffect(() => {
    const testConnection = async () => {
      console.log('üîç Testing connection to AI server...');
      try {
        const response = await callAIAssistant('test', sessionId);
        if (response.includes('kh√¥ng th·ªÉ k·∫øt n·ªëi')) {
          setConnectionStatus('failed');
        } else {
          setConnectionStatus('connected');
          console.log('‚úÖ Connection test successful');
        }
      } catch (error) {
        setConnectionStatus('failed');
        console.log('‚ùå Connection test failed:', error);
      }
    };
    
    testConnection();
  }, [sessionId]);

  // Ki·ªÉm tra k√≠ch th∆∞·ªõc m√†n h√¨nh
  useEffect(() => {
    const checkScreenSize = () => {
      const isMobileScreen = window.innerWidth <= 768 || 
                           (window.innerWidth < window.innerHeight && window.innerWidth <= 1024);
      setIsMobile(isMobileScreen);
    };

    checkScreenSize();
    window.addEventListener('resize', checkScreenSize);
    return () => window.removeEventListener('resize', checkScreenSize);
  }, []);

  // C·∫≠p nh·∫≠t th·ªùi gian
  useEffect(() => {
    const timer = setInterval(() => {
      setCurrentTime(
        new Date().toLocaleTimeString('en-US', { 
          hour: '2-digit', 
          minute: '2-digit', 
          second: '2-digit', 
          hour12: true 
        }) + ' +07, ' + new Date().toLocaleDateString('en-GB')
      );
    }, 1000);
    return () => clearInterval(timer);
  }, []);

  // Typing animation effect
  useEffect(() => {
    if (!speechText || !isTyping) return;
    
    let index = 0;
    setDisplayedText("");
    
    const timer = setInterval(() => {
      setDisplayedText(speechText.slice(0, index + 1));
      index++;
      
      if (index >= speechText.length) {
        clearInterval(timer);
        setIsTyping(false);
      }
    }, typingSpeed);
    
    return () => clearInterval(timer);
  }, [speechText, isTyping]);

  // T·ª± ƒë·ªông scroll xu·ªëng cu·ªëi khi c√≥ tin nh·∫Øn m·ªõi
  useEffect(() => {
    if (chatAreaRef.current) {
      chatAreaRef.current.scrollTop = chatAreaRef.current.scrollHeight;
    }
  }, [messages]);

  // Debug: Log session ID v√† connection status
  useEffect(() => {
    console.log('Session ID:', sessionId);
    console.log('Connection Status:', connectionStatus);
  }, [sessionId, connectionStatus]);

  // Audio player handlers
  function playerEnded() {
    setAudioSource(null);
    setSpeak(false);
    setPlaying(false);
  }

  function playerReady() {
    audioPlayer.current.audioEl.current.play();
    setPlaying(true);
  }

  // Chat handlers
  function handleTextChange(e) {
    const value = e.target.value.substring(0, 500);
    const cleanedText = cleanText(value);
    setText(cleanedText);
  }

  async function handleSend() {
    if (!text.trim() || isProcessing) return;

    const userMessage = {
      id: Date.now(),
      type: 'user',
      content: text.trim(),
      timestamp: new Date()
    };

    // C·∫≠p nh·∫≠t messages v·ªõi tin nh·∫Øn user
    const newMessages = [...messages, userMessage];
    setMessages(newMessages);

    // L∆∞u input v√† clear
    const currentInput = text.trim();
    setText("");
    setIsProcessing(true);

    try {
      console.log('üöÄ Sending message to AI:', currentInput);
      
      // G·ªçi AI API v·ªõi improved error handling
      const aiResponse = await callAIAssistant(currentInput, sessionId);
      
      console.log('ü§ñ AI Response received:', aiResponse);
      
      // T·∫°o tin nh·∫Øn AI
      const aiMessage = {
        id: Date.now() + 1,
        type: 'ai',
        content: aiResponse,
        timestamp: new Date()
      };
      
      // C·∫≠p nh·∫≠t messages v·ªõi ph·∫£n h·ªìi AI
      const updatedMessages = [...newMessages, aiMessage];
      setMessages(updatedMessages);
      
      // Ch·ªâ k√≠ch ho·∫°t speech n·∫øu kh√¥ng ph·∫£i error message
      if (!aiResponse.includes('kh√¥ng th·ªÉ k·∫øt n·ªëi')) {
        setSpeechText(aiResponse);
        setIsTyping(true);
        setSpeak(true);
        setConnectionStatus('connected');
      } else {
        setConnectionStatus('failed');
      }
      
    } catch (error) {
      console.error('üí• Error in handleSend:', error);
      
      // Th√™m tin nh·∫Øn l·ªói chi ti·∫øt h∆°n
      const errorMessage = {
        id: Date.now() + 1,
        type: 'ai',
        content: `Xin l·ªói, ƒë√£ x·∫£y ra l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu: ${error.message}. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi m·∫°ng v√† th·ª≠ l·∫°i.`,
        timestamp: new Date()
      };
      
      const updatedMessages = [...newMessages, errorMessage];
      setMessages(updatedMessages);
      setConnectionStatus('failed');
    }
    
    setIsProcessing(false);
  }

  function handleLogin() {
    navigate('/login');
  }

  function handleKeyPress(e) {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  }

  function handleVoiceChat() {
    alert('Ch·ª©c nƒÉng Voice Chat s·∫Ω ƒë∆∞·ª£c ph√°t tri·ªÉn trong t∆∞∆°ng lai!');
  }

  return (
    <div className={`container ${isMobile ? 'mobile-layout' : 'desktop-layout'}`}>
      {/* Header - hi·ªán tr√™n c√πng khi mobile */}
      {isMobile && (
        <div className="mobile-header">
          <div className="avatar-info">
            <div className="avatar-icon">A</div>
            <div className="avatar-name">
              Arwen AI 
              <span className={`connection-status ${connectionStatus}`}>
                {connectionStatus === 'connected' && 'üü¢'}
                {connectionStatus === 'failed' && 'üî¥'}
                {connectionStatus === 'checking' && 'üü°'}
              </span>
            </div>
          </div>
          <div className="header-right">
            <div className="current-time">{currentTime}</div>
            <button onClick={handleLogin} className="login-button">
              ƒêƒÉng nh·∫≠p
            </button>
          </div>
        </div>
      )}

      {/* Model 3D Panel */}
      <div className="model-panel">
        <Canvas dpr={2} onCreated={(ctx) => {
          ctx.gl.physicallyCorrectLights = true;
        }}>
          <OrthographicCamera
            makeDefault
            zoom={isMobile ? 800 : 1300}
            position={[0, 1.5, 1]}
          />

          <Suspense fallback={null}>
            <Environment background={false} files="/images/photo_studio_loft_hall_1k.hdr" />
          </Suspense>

          <Suspense fallback={null}>
            <Bg />
          </Suspense>

          <Suspense fallback={null}>
            <Avatar
              avatar_url="/model.glb"
              speak={speak}
              setSpeak={setSpeak}
              text={speechText}
              setAudioSource={setAudioSource}
              playing={playing}
            />
          </Suspense>
        </Canvas>
        <Loader dataInterpolation={(p) => `ƒêang t·∫£i... vui l√≤ng ƒë·ª£i`} />
        
        {/* Speech Bubble trong model */}
        {(displayedText || isTyping) && (
          <div className={`speech-bubble ${isMobile ? 'mobile-bubble' : ''}`}>
            <div className="bubble-text">
              {displayedText}
              {isTyping && <span className="typing-cursor">|</span>}
            </div>
            <div className="bubble-tail"></div>
          </div>
        )}
      </div>

      {/* Chat Panel */}
      <div className="chat-panel">
        {/* Header cho desktop */}
        {!isMobile && (
          <div className="header_model">
            <div className="avatar-info">
              <div className="avatar-icon">A</div>
              <div className="avatar-name">
                Arwen AI
                <span className={`connection-status ${connectionStatus}`}>
                  {connectionStatus === 'connected' && 'üü¢'}
                  {connectionStatus === 'failed' && 'üî¥'}
                  {connectionStatus === 'checking' && 'üü°'}
                </span>
              </div>
              {/* <div className="session-info">Session: {sessionId.substring(0, 8)}...</div> */}
              <div className="session-info">Session: {sessionId}</div>
            </div>
            <div className="header-right">
              <div className="current-time">{currentTime}</div>
              <button onClick={handleLogin} className="login-button">
                ƒêƒÉng nh·∫≠p
              </button>
            </div>
          </div>
        )}

        {/* Chat Messages - ch·ªâ hi·ªán tr√™n desktop */}
        {!isMobile && (
          <div className="chat-area" ref={chatAreaRef}>
            {/* Connection status message */}
            {connectionStatus === 'failed' && (
              <div className="message system-message">
                üî¥ L·ªói k·∫øt n·ªëi AI Server. ƒêang c·ªë g·∫Øng k·∫øt n·ªëi l·∫°i...
              </div>
            )}
            {connectionStatus === 'connected' && messages.length === 1 && (
              <div className="message system-message">
                üü¢ ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng v·ªõi AI Server!
              </div>
            )}
            
            {messages.map((message) => (
              <div
                key={message.id}
                className={`message ${message.type === 'user' ? 'user-message' : 'ai-message'}`}
              >
                {message.content}
              </div>
            ))}
            {/* Loading indicator */}
            {isProcessing && (
              <div className="message ai-message processing">
                <div className="typing-indicator">
                  <span></span>
                  <span></span>
                  <span></span>
                </div>
                ...
              </div>
            )}
          </div>
        )}

        {/* Input Area */}
        <div className={`input-area ${isMobile ? 'mobile-only-input' : ''}`}>
          <div className="input-container">
            <textarea
              className="text-input"
              value={text}
              onChange={handleTextChange}
              onKeyPress={handleKeyPress}
              placeholder="Nh·∫≠p tin nh·∫Øn c·ªßa b·∫°n..."
              rows={1}
              disabled={isProcessing}
            />
            <div className="button-group">
              <button
                onClick={handleSend}
                className={`send-button ${(!text.trim() || isProcessing) ? 'disabled-button' : ''}`}
                disabled={!text.trim() || isProcessing}
              >
                {isProcessing ? '...' : 'G·ª≠i'}
              </button>
              <button
                onClick={handleVoiceChat}
                className="voice-button"
                title="Voice Chat (Ch∆∞a kh·∫£ d·ª•ng)"
                disabled={isProcessing}
              >
                üé§
              </button>
            </div>
          </div>
        </div>
      </div>

      <ReactAudioPlayer
        src={audioSource}
        ref={audioPlayer}
        onEnded={playerEnded}
        onCanPlayThrough={playerReady}
      />
    </div>
  );
}

export default ModelDesign;